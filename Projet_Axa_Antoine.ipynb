{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet AXA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "import error_functions as ef\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# loading the train data\n",
    "data = pd.read_csv('data/train.csv', sep=\";\", parse_dates=['DATE'], index_col = ['DATE'], nrows = 10e6)\n",
    "data['DATE'] = data.index\n",
    "# data.head()\n",
    "\n",
    "# loading the test data\n",
    "submission = pd.read_csv('documentation/submission.txt', sep=\"\\t\", parse_dates=['DATE'], index_col = ['DATE'])\n",
    "submission['DATE'] = submission.index\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# timestamp exctraction\n",
    "def splitDatetime(data) :\n",
    "    datatime = pd.DatetimeIndex(data.DATE)\n",
    "    data['year'] = datatime.year\n",
    "    data['month'] = datatime.month\n",
    "    data['day'] = datatime.day\n",
    "    data['hour'] = datatime.hour\n",
    "    data['min'] = datatime.minute\n",
    "    data['workingday'] = (datatime.weekday < 6).astype(int)\n",
    "    return data\n",
    "\n",
    "data = splitDatetime(data)\n",
    "submission = splitDatetime(submission)\n",
    "# submission.head()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels/Features definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/dateutil/parser.py:98: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  while nextchar == '\\x00':\n",
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/dateutil/parser.py:123: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  elif nextchar == '.':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Téléphonie</th>\n",
       "      <th>RTC</th>\n",
       "      <th>Gestion Renault</th>\n",
       "      <th>Nuit</th>\n",
       "      <th>Gestion - Accueil Telephonique</th>\n",
       "      <th>Regulation Medicale</th>\n",
       "      <th>Services</th>\n",
       "      <th>Tech. Total</th>\n",
       "      <th>Gestion Relation Clienteles</th>\n",
       "      <th>Crises</th>\n",
       "      <th>...</th>\n",
       "      <th>Tech. Inter</th>\n",
       "      <th>Gestion Clients</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Tech. Axa</th>\n",
       "      <th>CAT</th>\n",
       "      <th>Gestion DZ</th>\n",
       "      <th>Mécanicien</th>\n",
       "      <th>CMS</th>\n",
       "      <th>Prestataires</th>\n",
       "      <th>Evenements</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:30:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Téléphonie  RTC  Gestion Renault  Nuit  \\\n",
       "DATE                                                          \n",
       "2011-01-01 00:00:00         0.0  0.0              0.0  13.0   \n",
       "2011-01-01 00:30:00         1.0  0.0              0.0  16.0   \n",
       "2011-01-01 01:00:00         0.0  0.0              0.0  20.0   \n",
       "2011-01-01 01:30:00         0.0  0.0              0.0  21.0   \n",
       "2011-01-01 02:00:00         0.0  0.0              0.0  28.0   \n",
       "\n",
       "                     Gestion - Accueil Telephonique  Regulation Medicale  \\\n",
       "DATE                                                                       \n",
       "2011-01-01 00:00:00                             0.0                  0.0   \n",
       "2011-01-01 00:30:00                             0.0                  0.0   \n",
       "2011-01-01 01:00:00                             0.0                  0.0   \n",
       "2011-01-01 01:30:00                             0.0                  0.0   \n",
       "2011-01-01 02:00:00                             0.0                  0.0   \n",
       "\n",
       "                     Services  Tech. Total  Gestion Relation Clienteles  \\\n",
       "DATE                                                                      \n",
       "2011-01-01 00:00:00       0.0          0.0                          0.0   \n",
       "2011-01-01 00:30:00       3.0          0.0                          0.0   \n",
       "2011-01-01 01:00:00       0.0          0.0                          0.0   \n",
       "2011-01-01 01:30:00       0.0          0.0                          0.0   \n",
       "2011-01-01 02:00:00       2.0          0.0                          0.0   \n",
       "\n",
       "                     Crises     ...      Tech. Inter  Gestion Clients  \\\n",
       "DATE                            ...                                     \n",
       "2011-01-01 00:00:00     0.0     ...              0.0              0.0   \n",
       "2011-01-01 00:30:00     0.0     ...              0.0              0.0   \n",
       "2011-01-01 01:00:00     0.0     ...              0.0              0.0   \n",
       "2011-01-01 01:30:00     0.0     ...              0.0              0.0   \n",
       "2011-01-01 02:00:00     0.0     ...              0.0              0.0   \n",
       "\n",
       "                     Manager  Tech. Axa  CAT  Gestion DZ  Mécanicien  CMS  \\\n",
       "DATE                                                                        \n",
       "2011-01-01 00:00:00      0.0        0.0  0.0         0.0         0.0  0.0   \n",
       "2011-01-01 00:30:00      0.0        0.0  0.0         0.0         0.0  0.0   \n",
       "2011-01-01 01:00:00      0.0        0.0  0.0         0.0         0.0  0.0   \n",
       "2011-01-01 01:30:00      0.0        0.0  0.0         0.0         0.0  0.0   \n",
       "2011-01-01 02:00:00      0.0        0.0  0.0         0.0         0.0  0.0   \n",
       "\n",
       "                     Prestataires  Evenements  \n",
       "DATE                                           \n",
       "2011-01-01 00:00:00           0.0         0.0  \n",
       "2011-01-01 00:30:00           0.0         0.0  \n",
       "2011-01-01 01:00:00           0.0         0.0  \n",
       "2011-01-01 01:30:00           0.0         0.0  \n",
       "2011-01-01 02:00:00           0.0         0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame()\n",
    "X = data[['year','month','day','hour','ASS_ASSIGNMENT','CSPL_CALLS','min','DATE']]\n",
    "df1 = X.pivot_table(index = ['DATE'], columns = ['ASS_ASSIGNMENT'], values = ['CSPL_CALLS'], aggfunc=np.sum)\n",
    "# print(df1.shape)\n",
    "df1.fillna(0, inplace=True)\n",
    "# df1.head()\n",
    "\n",
    "y_df = pd.DataFrame()\n",
    "for cat in data.ASS_ASSIGNMENT.unique() :\n",
    "    y_df[cat] = df1['CSPL_CALLS'][cat]\n",
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index = submission.index)\n",
    "X_test['DATE'] = submission.index\n",
    "X_test = splitDatetime(X_test)\n",
    "X_test.drop('DATE', axis=1, inplace=True)\n",
    "X_test = X_test.drop_duplicates()\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data first date : 2011-01-01 00:00:00\n",
      "train data last date  : 2013-12-31 14:30:00\n",
      "train data range : 11 months and 30 days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(index = y_df.index)\n",
    "X_train['DATE'] = y_df.index\n",
    "X_train = splitDatetime(X_train)\n",
    "X_train.drop('DATE', axis=1, inplace=True)\n",
    "# X_train.head()\n",
    "\n",
    "date_min = X_train.index.min()\n",
    "date_max = X_train.index.max()\n",
    "X_train_range = relativedelta.relativedelta(date_max, date_min)\n",
    "\n",
    "print('train data first date : %s' %date_min)\n",
    "print('train data last date  : %s' %date_max)\n",
    "print('train data range : %s months and %s days\\n' %(X_train_range.months,X_train_range.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV data first date : 2013-12-29 00:00:00\n",
      "CV data last date  : 2013-12-31 14:30:00\n",
      "CV data range : 0 months and 2 days\n"
     ]
    }
   ],
   "source": [
    "X_train_CV = X_train.last('7d')\n",
    "\n",
    "date_min_CV = X_train_CV.index.min()\n",
    "date_max_CV = X_train_CV.index.max()\n",
    "X_CV_range = relativedelta.relativedelta(date_max_CV, date_min_CV)\n",
    "\n",
    "print('CV data first date : %s' %date_min_CV)\n",
    "print('CV data last date  : %s' %date_max_CV)\n",
    "print('CV data range : %s months and %s days' %(X_CV_range.months,X_CV_range.days))\n",
    "# X_train_CV.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data anterior to prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = X_train.truncate(after=date_min_CV)\n",
    "\n",
    "date_min = X_train.index.min()\n",
    "date_max = X_train.index.max()\n",
    "X_train_range = relativedelta.relativedelta(date_max, date_min)\n",
    "\n",
    "print('train data first date : %s' %date_min)\n",
    "print('train data last date  : %s' %date_max)\n",
    "print('train data range : %s months and %s days\\n' %(X_train_range.months,X_train_range.days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features from last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set number of hours prediction is in advance\n",
    "n_periods_advance = 336#*7*24*2 #336\n",
    "# period_advance = \"1W\"\n",
    "\n",
    "# Set number of historic hours used\n",
    "n_periods_window = 24#7*24*2 #178\n",
    "# period_window = '1W'\n",
    "\n",
    "# Set number of historic hours in advance\n",
    "for cat in y_df:\n",
    "    if cat not in ['Evenements','Gestion Amex']:\n",
    "        for k in range(n_periods_advance,n_periods_advance+n_periods_window):    \n",
    "            X_test['%s_t-%i'%(cat.decode('utf-8'),k)] = y_df[cat].shift(k*30, freq='min')\n",
    "            X_train['%s_t-%i'%(cat.decode('utf-8'),k)] = y_df[cat].shift(k)\n",
    "\n",
    "X_train.drop(X_train.index[:n_periods_window+n_periods_advance], inplace=True)\n",
    "y_df.drop(y_df.index[:n_periods_window+n_periods_advance], inplace=True)\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as pre\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "        return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#from xgboost import plot_importance\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 20\n",
    "        pca = PCA(n_components=self.n_components)\n",
    "        selection = SelectKBest(k = 5)\n",
    "        combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "        self.reg = Pipeline([\n",
    "            #('cf', combined_features),\n",
    "            #('pca', PCA(n_components = self.n_components)),\n",
    "            ('xgb', xgb.XGBRegressor(\n",
    "                learning_rate = 0.1,\n",
    "                n_estimators = 100,\n",
    "                max_depth = 2,\n",
    "                min_child_weight = 1,\n",
    "                gamma = 0.2,\n",
    "                subsample = 0.9,\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.reg.predict_proba(X)\n",
    "    \n",
    "    def grid_search_fit(self, X, y):\n",
    "        y = y.astype(float)\n",
    "        # use a full grid over all parameters\n",
    "        param_grid = dict(\n",
    "            # pca__n_components = [10,20,40],\n",
    "            xgb__max_depth = [3,10,2],#[10,11,9]#[9,10,11],#\n",
    "            xgb__min_child_weight = [1,6,2],\n",
    "            # xgb__gamma = [i/10.0 for i in range(0,5)]\n",
    "            # xgb__subsample = [i/10.0 for i in range(6,10)],\n",
    "            # xgb__colsample_bytree = [i/10.0 for i in range(6,10)]\n",
    "            )\n",
    "\n",
    "        param_grid_rfr = dict(\n",
    "            max_leaf_nodes = [9,10,11],\n",
    "            max_depth = [3, None],\n",
    "            max_features = [1, 3, 10],\n",
    "            min_samples_split = [3, 10],\n",
    "            min_samples_leaf = [1, 3, 10],\n",
    "            bootstrap = [True, False]\n",
    "            )\n",
    "\n",
    "        # error definition\n",
    "        linex = make_scorer(ef.linex_loss, greater_is_better = False)\n",
    "\n",
    "        grid_search = GridSearchCV(self.reg, param_grid = param_grid, scoring = linex)#, verbose = 10)\n",
    "\n",
    "        # fit gridsearch\n",
    "        self.reg = grid_search.fit(X, y)\n",
    "\n",
    "        print('Grid search  best score: %.3f' % grid_search.best_score_)\n",
    "        print('Grid search  best params:')\n",
    "        for k, v in sorted(grid_search.best_params_.items()):\n",
    "            print(\"\\t%s: %r\" % (k, v))\n",
    "        # get best estimator\n",
    "        self.reg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléphonie\n",
      "------------------------------------------------\n",
      "9594\n",
      "9594\n",
      "3085\n",
      "3085\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Téléphonie... Done.\n",
      "Testing algorithm for Téléphonie... Done.\n",
      "error Téléphonie = 239\n",
      "\n",
      "------------------------------------------------\n",
      "RTC\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for RTC... Done.\n",
      "Testing algorithm for RTC... Done.\n",
      "error RTC = 7\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Renault\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Renault... Done.\n",
      "Testing algorithm for Gestion Renault... Done.\n",
      "error Gestion Renault = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Nuit\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Nuit... Done.\n",
      "Testing algorithm for Nuit... Done.\n",
      "error Nuit = 56\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion - Accueil Telephonique\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion - Accueil Telephonique... Done.\n",
      "Testing algorithm for Gestion - Accueil Telephonique... Done.\n",
      "error Gestion - Accueil Telephonique = 44\n",
      "\n",
      "------------------------------------------------\n",
      "Regulation Medicale\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Regulation Medicale... Done.\n",
      "Testing algorithm for Regulation Medicale... Done.\n",
      "error Regulation Medicale = 2\n",
      "\n",
      "------------------------------------------------\n",
      "Services\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Services... Done.\n",
      "Testing algorithm for Services... Done.\n",
      "error Services = 65\n",
      "\n",
      "------------------------------------------------\n",
      "Tech. Total\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Total... Done.\n",
      "Testing algorithm for Tech. Total... Done.\n",
      "error Tech. Total = 166\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Relation Clienteles\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Relation Clienteles... Done.\n",
      "Testing algorithm for Gestion Relation Clienteles... Done.\n",
      "error Gestion Relation Clienteles = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Crises\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Crises... Done.\n",
      "Testing algorithm for Crises... Done.\n",
      "error Crises = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Japon\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Japon... Done.\n",
      "Testing algorithm for Japon... Done.\n",
      "error Japon = 1\n",
      "\n",
      "------------------------------------------------\n",
      "Médical\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Médical... Done.\n",
      "Testing algorithm for Médical... Done.\n",
      "error Médical = 56\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Assurances\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Assurances... Done.\n",
      "Testing algorithm for Gestion Assurances... Done.\n",
      "error Gestion Assurances = 1\n",
      "\n",
      "------------------------------------------------\n",
      "Domicile\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Domicile... Done.\n",
      "Testing algorithm for Domicile... Done.\n",
      "error Domicile = 75\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion... Done.\n",
      "Testing algorithm for Gestion... Done.\n",
      "error Gestion = 0\n",
      "\n",
      "------------------------------------------------\n",
      "SAP\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for SAP... Done.\n",
      "Testing algorithm for SAP... Done.\n",
      "error SAP = 4\n",
      "\n",
      "------------------------------------------------\n",
      "RENAULT\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for RENAULT... Done.\n",
      "Testing algorithm for RENAULT... Done.\n",
      "error RENAULT = 37\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Amex\n",
      "pass.\n",
      "------------------------------------------------\n",
      "Tech. Inter\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Inter... Done.\n",
      "Testing algorithm for Tech. Inter... Done.\n",
      "error Tech. Inter = 115\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Clients\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Clients... Done.\n",
      "Testing algorithm for Gestion Clients... Done.\n",
      "error Gestion Clients = 1\n",
      "\n",
      "------------------------------------------------\n",
      "Manager\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Manager... Done.\n",
      "Testing algorithm for Manager... Done.\n",
      "error Manager = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Tech. Axa\n",
      "------------------------------------------------\n",
      "9594\n",
      "9594\n",
      "3085\n",
      "3085\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Axa... Done.\n",
      "Testing algorithm for Tech. Axa... Done.\n",
      "error Tech. Axa = 28173\n",
      "\n",
      "------------------------------------------------\n",
      "CAT\n",
      "------------------------------------------------\n",
      "9594\n",
      "9594\n",
      "3085\n",
      "3085\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for CAT... Done.\n",
      "Testing algorithm for CAT... Done.\n",
      "error CAT = 8802\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion DZ\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion DZ... Done.\n",
      "Testing algorithm for Gestion DZ... Done.\n",
      "error Gestion DZ = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Mécanicien\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Mécanicien... Done.\n",
      "Testing algorithm for Mécanicien... Done.\n",
      "error Mécanicien = 1\n",
      "\n",
      "------------------------------------------------\n",
      "CMS\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for CMS... Done.\n",
      "Testing algorithm for CMS... Done.\n",
      "error CMS = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Prestataires\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Prestataires... Done.\n",
      "Testing algorithm for Prestataires... Done.\n",
      "error Prestataires = 0\n",
      "\n",
      "------------------------------------------------\n",
      "Evenements\n",
      "pass.\n",
      "------------------------------------------------\n",
      "train sample size % total sample size = 97.44%\n",
      "error = 37848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Regressor, GS):\n",
    "    \n",
    "    y_train_reg = {}\n",
    "    y_test_reg = {}\n",
    "    reg = {}\n",
    "    y_pred_reg = {}\n",
    "    error = 0\n",
    "    \n",
    "    for cat in data.ASS_ASSIGNMENT.unique():\n",
    "        print('%s' %cat.decode('utf-8'))\n",
    "        if cat not in ['Evenements','Gestion Amex']:\n",
    "            print('------------------------------------------------')\n",
    "            # Spliting data for cross validation\n",
    "            train_is, test_is = skf_is\n",
    "            \n",
    "            # test/train definition\n",
    "            X_train_df = X_df.iloc[train_is].copy()\n",
    "            base_col = ['year','month','day','hour','min','workingday']\n",
    "            filter_col = [col for col in list(X_train_df) if (col.startswith(cat.decode('utf-8')) or col in base_col)]\n",
    "            X_train_df = X_train_df[filter_col]\n",
    "            y_train_df = y_df.iloc[train_is].copy()\n",
    "            X_test_df = X_df.iloc[test_is].copy()\n",
    "            X_test_df = X_test_df[filter_col]\n",
    "            y_test_df = y_df.iloc[test_is].copy()\n",
    "            \n",
    "            \n",
    "            if cat in ['Tech. Axa','Téléphonie','CAT']:\n",
    "                X_train_df = X_train_df.last('3m')\n",
    "                y_train_df = y_train_df.last('3m')\n",
    "\n",
    "            # casual/registered definition\n",
    "            y_train_reg[cat] = y_train_df[cat].values\n",
    "            y_test_reg[cat] = y_test_df[cat].values\n",
    "            # y_test_reg = y_test_df['count'].values\n",
    "            print(\"Done.\")\n",
    "\n",
    "            # Features extraction (no modification of data in this case)\n",
    "            print(\"Exctracting features ...\"),\n",
    "            fe_reg = FeatureExtractor()\n",
    "            fe_reg.fit(X_train_df, y_train_df)\n",
    "            X_train_array_reg = fe_reg.transform(X_train_df)\n",
    "            X_test_array_reg = fe_reg.transform(X_test_df)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            # Train\n",
    "            print(\"Training algorithm for %s...\" %cat.decode('utf-8')),\n",
    "            # regressors initialisation\n",
    "            reg[cat] = Regressor()\n",
    "\n",
    "            # grid search to calibrate model before fitting\n",
    "            if GS :\n",
    "                if cat in ['Tech. Axa','Téléphonie','CAT']:\n",
    "                    reg[cat].grid_search_fit(X_train_array_reg, y_train_reg[cat])\n",
    "\n",
    "            # fitting model\n",
    "            reg[cat].fit(X_train_array_reg, y_train_reg[cat])\n",
    "            print(\"Done.\")\n",
    "\n",
    "            # Test\n",
    "            print(\"Testing algorithm for %s...\" %cat.decode('utf-8')),\n",
    "            y_pred_reg[cat] = np.round(reg[cat].predict(X_test_array_reg),0)\n",
    "            error_tmp = ef.linex_loss(y_pred_reg[cat], y_test_reg[cat])\n",
    "            error += error_tmp\n",
    "\n",
    "            print(\"Done.\")\n",
    "            print('error %s = %.0f' %(cat.decode('utf-8'),error_tmp))\n",
    "            print('\\n------------------------------------------------')\n",
    "        else:\n",
    "            print(\"pass.\")\n",
    "            print('------------------------------------------------')\n",
    "    k = X_train_df.shape[0]+X_test_df.shape[0]\n",
    "    l = X_train_df.shape[0]\n",
    "    print('train sample size %% total sample size = %.2f%%' %(100*float(l)/k))\n",
    "    print('error = %.0f' %(error))\n",
    "\n",
    "#skf = ShuffleSplit(n_splits=2)\n",
    "#skf_is = list(skf.split(X_train))[0]\n",
    "a = X_train.shape[0]\n",
    "b = X_train_CV.shape[0]\n",
    "#print(skf_is)\n",
    "#prop = 0.9\n",
    "skf_is = ([np.arange(a-b).astype(int),np.arange(a-b,a).astype(int)])\n",
    "#print(skf_is)\n",
    "\n",
    "train_test_model_clf(X_train, y_df, skf_is, FeatureExtractor, Regressor, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMS\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for CMS... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Crises\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Crises... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Domicile\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Domicile... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion - Accueil Telephonique\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion - Accueil Telephonique... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Assurances\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Assurances... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Relation Clienteles\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Relation Clienteles... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Renault\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Renault... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Japon\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Japon... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Médical\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Médical... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Nuit\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Nuit... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "RENAULT\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for RENAULT... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Regulation Medicale\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Regulation Medicale... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "SAP\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for SAP... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Services\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Services... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Tech. Axa\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Axa... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Tech. Inter\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Inter... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Téléphonie\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Téléphonie... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Tech. Total\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Tech. Total... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Mécanicien\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Mécanicien... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "CAT\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for CAT... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Manager\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Manager... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion Clients\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion Clients... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Gestion DZ\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Gestion DZ... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "RTC\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for RTC... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "Prestataires\n",
      "------------------------------------------------\n",
      "Done.\n",
      "Exctracting features ... Done.\n",
      "Training algorithm for Prestataires... Done.\n",
      "\n",
      "------------------------------------------------\n",
      "saved in file\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_test_model_clf(X_train, X_test, y_train, FeatureExtractor):\n",
    "    \n",
    "    y_train_reg = {}\n",
    "    y_test_reg = {}\n",
    "    reg = {}\n",
    "    y_pred_reg = {}\n",
    "    error = 0\n",
    "    first = True\n",
    "    y_pred = np.zeros((submission.shape[0]))\n",
    "    \n",
    "    for cat in submission.ASS_ASSIGNMENT.unique():\n",
    "        print('%s' %cat.decode('utf-8'))\n",
    "        if cat not in ['Evenements','Gestion Amex']:\n",
    "            print('------------------------------------------------')\n",
    "\n",
    "            # test/train definition  \n",
    "            X_train_df = X_train.copy()\n",
    "            y_train_df = y_train.copy()\n",
    "            X_test_df = X_test.copy()\n",
    "            \n",
    "            base_col = ['year','month','day','hour','min','workingday']\n",
    "            filter_col = [col for col in list(X_train_df) if (col.startswith(cat.decode('utf-8')) or col in base_col)]          \n",
    "            X_test_df = X_test_df[filter_col]\n",
    "            X_train_df = X_train_df[filter_col]\n",
    "            \n",
    "            if cat in ['Tech. Axa','Téléphonie','CAT']:\n",
    "                X_train_df = X_train_df.last('6m')\n",
    "                y_train_df = y_train_df.last('6m')\n",
    "\n",
    "            # cat definition\n",
    "            y_train_reg[cat] = y_train_df[cat].values\n",
    "            print(\"Done.\")\n",
    "\n",
    "            # Features extraction (no modification of data in this case)\n",
    "            print(\"Exctracting features ...\"),\n",
    "            fe_reg = FeatureExtractor()\n",
    "            fe_reg.fit(X_train_df, y_train_df)\n",
    "            X_train_array_reg = fe_reg.transform(X_train_df)\n",
    "            X_test_array_reg = fe_reg.transform(X_test_df)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            # Train\n",
    "            print(\"Training algorithm for %s...\" %cat.decode('utf-8')),\n",
    "            # regressors initialisation\n",
    "            reg[cat] = Regressor()\n",
    "\n",
    "            # uncomment to perform grid search to calibrate model before fitting\n",
    "            #if cat in ['Tech. Axa','Téléphonie','CAT']:\n",
    "            #    reg[cat].grid_search_fit(X_train_array_reg, y_train_reg[cat])\n",
    "\n",
    "            # fitting model\n",
    "            reg[cat].fit(X_train_array_reg, y_train_reg[cat])            \n",
    "            print(\"Done.\")\n",
    "            print('\\n------------------------------------------------')\n",
    "        else:\n",
    "            print(\"pass.\")\n",
    "            print('------------------------------------------------')\n",
    "    rep = pd.DataFrame(index = submission.index)\n",
    "    #print(rep.shape)\n",
    "    rep['DATE'] = submission.index\n",
    "    rep['ASS_ASSIGNMENT'] = submission.ASS_ASSIGNMENT\n",
    "    i = 0\n",
    "    \n",
    "    for index, row in rep.iterrows():\n",
    "        cat = row['ASS_ASSIGNMENT']\n",
    "        y_pred[i] = reg[cat].predict(X_test.loc[index])[0].astype(int)\n",
    "        i+=1\n",
    "    rep['prediction'] = np.maximum(y_pred.astype(int),0)\n",
    "\n",
    "    print(\"saved in file\")\n",
    "    \n",
    "    rep.to_csv(\"submission_test.txt\", sep=\"\\t\", index=False)\n",
    "    \n",
    "train_test_model_clf(X_train, X_test, y_df, FeatureExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read.\n",
      "Data modified.\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"submission_test.txt\"\n",
    "output_file = \"submission_test_modif.txt\"\n",
    "\n",
    "modif = pd.read_csv(input_file, sep=\"\\t\")\n",
    "print(\"File read.\")\n",
    "modif['DATE'] = [dd + \".000\" for dd in modif['DATE']]\n",
    "print(\"Data modified.\")\n",
    "modif.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "print(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
