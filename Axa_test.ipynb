{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Projet AXA </h1>\n",
    "\n",
    "<h2> Raphaël Meudec, Guillaume Richard, Antoine Simoulin </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "import error_functions as ef\n",
    "from dateutil import relativedelta\n",
    "from workalendar.europe import France\n",
    "# pip install workalendar\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as mpl\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:878: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# colors for plot\n",
    "blue_light = '#029aed'\n",
    "orange_med = '#ff5722'\n",
    "green_light = '#63a600'\n",
    "gray_light = '#666666'\n",
    "blue_AXA = '#103184'\n",
    "red_AXA = '#ff1821'\n",
    "cal = France()\n",
    "# set colors for graphs\n",
    "mpl.rcParams['axes.color_cycle'] = [blue_AXA, red_AXA, gray_light]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create DataFrame with public holliday in France for years 2011, 2012, 2013, 2014\n",
    "holiday_map = pd.DataFrame()\n",
    "for year in [2011,2012,2013,2014]:\n",
    "    holiday_map_temp = pd.DataFrame(cal.holidays(year))\n",
    "    holiday_map_temp = holiday_map_temp.set_index([0])\n",
    "    holiday_map = pd.concat([holiday_map, holiday_map_temp], ignore_index=False)\n",
    "# holiday_map.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the train data\n",
    "data = pd.read_csv('data/train.csv', sep=\";\", parse_dates=['DATE'], index_col = ['DATE'], nrows = 3*1e4)\n",
    "data['DATE'] = data.index\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# timestamp exctraction\n",
    "def splitDatetime(data) :\n",
    "    datatime = pd.DatetimeIndex(data.DATE)\n",
    "    data['year'] = datatime.year\n",
    "    data['month'] = datatime.month\n",
    "    data['day'] = datatime.day\n",
    "    data['hour'] = datatime.hour\n",
    "    data['min'] = datatime.minute\n",
    "    data['dayweek'] = datatime.weekday\n",
    "    data['workingday'] = (datatime.weekday < 6).astype(int)\n",
    "    data['holiday'] = data.index.isin(holiday_map.index).astype(int)\n",
    "    data['night'] = (datatime.hour < 7).astype(int)\n",
    "    return data\n",
    "\n",
    "data = splitDatetime(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/dateutil/parser.py:98: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  while nextchar == '\\x00':\n",
      "/Users/Antoine/anaconda2/lib/python2.7/site-packages/dateutil/parser.py:123: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  elif nextchar == '.':\n"
     ]
    }
   ],
   "source": [
    "def format_label():\n",
    "    # pivot table on data for ASS_ASSIGNMENT columnwise\n",
    "    X = pd.DataFrame()\n",
    "    X = data[['year','month','day','hour','ASS_ASSIGNMENT','CSPL_CALLS','min','DATE']]\n",
    "    df1 = X.pivot_table(index = ['DATE'], columns = ['ASS_ASSIGNMENT'], values = ['CSPL_CALLS'], aggfunc=np.sum)\n",
    "    # print(df1.shape)\n",
    "    # when data for this date an categorie not available, fill with 0\n",
    "    df1.fillna(0, inplace=True)\n",
    "    # df1.head()\n",
    "\n",
    "    # creating labels, ASS_ASSIGNMENT are presented columnwise thanks to pivot table above\n",
    "    y_df = pd.DataFrame()\n",
    "    for cat in data.ASS_ASSIGNMENT.unique() :\n",
    "        y_df[cat] = df1['CSPL_CALLS'][cat]\n",
    "    y_df.head()\n",
    "    \n",
    "    return y_df\n",
    "    \n",
    "y_df = format_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_train(y_df):\n",
    "    \n",
    "    # formatting train data\n",
    "    X_train = pd.DataFrame(index = y_df.index)\n",
    "    X_train['DATE'] = y_df.index\n",
    "    X_train = splitDatetime(X_train)\n",
    "    X_train.drop('DATE', axis=1, inplace=True)\n",
    "    \n",
    "    date_min = X_train.index.min()\n",
    "    date_max = X_train.index.max()\n",
    "    X_train_range = relativedelta.relativedelta(date_max, date_min)\n",
    "\n",
    "    # print train data range\n",
    "    print('train data first date : %s' %date_min)\n",
    "    print('train data last date  : %s' %date_max)\n",
    "    print('train data range : %s years, %s months and %s days\\n' %(X_train_range.years, X_train_range.months,X_train_range.days))\n",
    "    # X_train.head()\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to split data for CV purposes\n",
    "# algorithm is test on last week of the randomly choosen train data set\n",
    "\n",
    "def split_data(X_train):\n",
    "    \n",
    "    X_train_split = X_train\n",
    "    # the subset contain at leat 50% of the original data\n",
    "    s = np.random.uniform(X_train_split.shape[0]*0.9,X_train_split.shape[0],1).astype(int)\n",
    "    X_train_split.drop(X_train_split.index[s:], inplace=True)\n",
    "\n",
    "    date_min = X_train.index.min()\n",
    "    date_max = X_train.index.max()\n",
    "    X_train_range = relativedelta.relativedelta(date_max, date_min)\n",
    "\n",
    "    # print subset range\n",
    "    print('train data first date : %s' %date_min)\n",
    "    print('train data last date  : %s' %date_max)\n",
    "    print('train data range : %s years, %s months and %s days\\n' %(X_train_range.years, X_train_range.months,X_train_range.days))\n",
    "    # X_train.head()\n",
    "    \n",
    "    # Last week of the subset is used for cross validation purposes\n",
    "    X_train_split_CV = X_train_split.last('7d')\n",
    "    date_min_CV = X_train_split_CV.index.min()\n",
    "    date_max_CV = X_train_split_CV.index.max()\n",
    "    X_CV_range = relativedelta.relativedelta(date_max_CV, date_min_CV)\n",
    "\n",
    "    # print CV subset week range\n",
    "    print('CV data first date : %s' %date_min_CV)\n",
    "    print('CV data last date  : %s' %date_max_CV)\n",
    "    print('CV data range : %s years, %s months and %s days' %(X_CV_range.years, X_CV_range.months,X_CV_range.days))\n",
    "    # X_train_CV.head()\n",
    "    \n",
    "    return X_train_split, X_train_split_CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as pre\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "        return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is log likelihood loss\n",
    "def custom_obj(y_true, y_pred):\n",
    "    grad = 0.1*exp(y_true-y_pred)\n",
    "    hess = 0.1**2*np.exp(0.1*(y_true-y_pred))\n",
    "    grad = xgb.DMtarix(grad)\n",
    "    hess = xgb.DMatrix(hess)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    \n",
    "    def custom_obj(y_true, y_pred):\n",
    "        grad = 0.1*exp(y_true-y_pred)\n",
    "        hess = 0.1**2*np.exp(0.1*(y_true-y_pred))\n",
    "        # grad = xgb.DMtarix(grad)\n",
    "        # hess = xgb.DMatrix(hess)\n",
    "        return grad, hess\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.reg_std = Pipeline([\n",
    "            ('xgb', xgb.XGBRegressor(\n",
    "                objective = custom_obj#'reg:linear',##\n",
    "                #learning_rate = 0.1,\n",
    "                #n_estimators = 100,\n",
    "                #max_depth = 2,\n",
    "                #min_child_weight = 1,\n",
    "                #gamma = 0.1,\n",
    "                #subsample = 0.9,\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.reg_std.fit(X, y)\n",
    "        #return xgb.train(param, dtrain, num_round, watchlist, obj=softkappaobj, feval=evalerror)\n",
    "\n",
    "    def predict(self, X, cat):\n",
    "        return self.reg_std.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.reg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linex_err(y_pred, y_train):\n",
    "    return np.sum(0.1*np.exp(y_train-y_pred)-0.1*(y_train-y_pred))-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data first date : 2011-01-01 00:00:00\n",
      "train data last date  : 2011-04-30 01:30:00\n",
      "train data range : 0 years, 3 months and 29 days\n",
      "\n",
      "train data first date : 2011-01-01 00:00:00\n",
      "train data last date  : 2011-04-25 00:30:00\n",
      "train data range : 0 years, 3 months and 24 days\n",
      "\n",
      "CV data first date : 2011-04-18 01:00:00\n",
      "CV data last date  : 2011-04-25 00:30:00\n",
      "CV data range : 0 years, 0 months and 6 days\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e1ced4393a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mskf_is\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtrain_test_model_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskf_is\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-e1ced4393a6f>\u001b[0m in \u001b[0;36mtrain_test_model_clf\u001b[0;34m(X_df, y_df, skf_is, FeatureExtractor, Regressor, GS)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# regressors initialisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mreg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# fitting model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-295b87973625>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         self.reg_std = Pipeline([\n\u001b[1;32m     17\u001b[0m             ('xgb', xgb.XGBRegressor(\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_obj\u001b[0m\u001b[0;31m#'reg:linear',##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;31m#learning_rate = 0.1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m#n_estimators = 100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'obj'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Regressor, GS):\n",
    "    \n",
    "    y_train_reg = {}\n",
    "    y_test_reg = {}\n",
    "    y_pred_reg = {}\n",
    "    reg = {}\n",
    "    error = 0\n",
    "    \n",
    "    for cat in data.ASS_ASSIGNMENT.unique():\n",
    "        if cat in ['Téléphonie'] :\n",
    "\n",
    "            # Spliting data for cross validation\n",
    "            train_is, test_is = skf_is\n",
    "            \n",
    "            # test/train definition\n",
    "            X_train_df = X_df.iloc[train_is].copy()\n",
    "            y_train_df = y_df.iloc[train_is].copy()\n",
    "            X_test_df = X_df.iloc[test_is].copy()\n",
    "            y_test_df = y_df.iloc[test_is].copy()\n",
    "            \n",
    "            \n",
    "            # for téléphonie only use last 6 month because data range to vary a lot each year\n",
    "            if cat in ['Téléphonie','Tech. Axa','CAT']:\n",
    "                X_train_df = X_train_df.last('3m')\n",
    "                y_train_df = y_train_df.last('3m')\n",
    "\n",
    "            # label category definition\n",
    "            y_train_reg[cat] = y_train_df[cat].values\n",
    "            y_test_reg[cat] = y_test_df[cat].values\n",
    "\n",
    "            # Features extraction (no modification of data in this case)\n",
    "            fe_reg = FeatureExtractor()\n",
    "            fe_reg.fit(X_train_df, y_train_df)\n",
    "            X_train_array_reg = fe_reg.transform(X_train_df)\n",
    "            X_test_array_reg = fe_reg.transform(X_test_df)\n",
    "\n",
    "            # Train\n",
    "            # regressors initialisation\n",
    "            reg[cat] = Regressor()\n",
    "\n",
    "            # fitting model\n",
    "            reg[cat].fit(X_train_array_reg, y_train_reg[cat])\n",
    "\n",
    "            # Test\n",
    "            y_pred_reg[cat] = np.round(np.maximum(reg[cat].predict(X_test_array_reg,cat),0),0)            \n",
    "            error_tmp = linex_err(y_pred_reg[cat], y_test_reg[cat])\n",
    "            error += error_tmp\n",
    "            print('error %s = %.1f' %(cat.decode('utf-8'),error_tmp))\n",
    "            \n",
    "            # plot figure for predicted week\n",
    "            y_test_plt = pd.DataFrame(index = y_test_df.index)\n",
    "            y_test_plt[cat.decode('utf-8')] = y_test_reg[cat]\n",
    "            y_pred_plt = pd.DataFrame(index = y_test_df.index)\n",
    "            y_pred_plt[cat.decode('utf-8')] = y_pred_reg[cat]\n",
    "            \n",
    "            fig = plt.figure(figsize=[15,4])\n",
    "            plt.style.use('ggplot')\n",
    "            plt.plot(y_test_plt[cat.decode('utf-8')], color = blue_AXA)\n",
    "            plt.plot(y_pred_plt[cat.decode('utf-8')], linestyle = 'dashed', color=red_AXA, linewidth=2)\n",
    "            plt.title('error on predected week for %s (error = %.1f)' %(cat.decode('utf-8'),error_tmp))\n",
    "            plt.legend(['true','pred'],loc='best')\n",
    "            fig.savefig('plots/Pred_appels_categorie_%s.png' %(cat),bbox_inches='tight')\n",
    "            \n",
    "            #print('\\n------------------------------------------------')\n",
    "        #else:\n",
    "            #print(\"pass.\")\n",
    "            #print('------------------------------------------------')\n",
    "    k = X_train_df.shape[0]+X_test_df.shape[0]\n",
    "    l = X_train_df.shape[0]\n",
    "    print('train sample size %% total sample size = %.2f%%' %(100*float(l)/k))\n",
    "    print('error = %.1f' %(error))\n",
    "\n",
    "# define training set\n",
    "X_train = format_train(y_df)\n",
    "# splitting sample for CV : \n",
    "# take a radom part of the train sample (at least 50% of the original data size) and the last week to test results\n",
    "X_train_1, X_train_CV = split_data(X_train)\n",
    "\n",
    "# to avoid numerical problems, each values of the features is defined as a new feature\n",
    "X_train_1 = pd.get_dummies(data=X_train_1, columns=['year','hour','min','dayweek'])\n",
    "X_train_CV = pd.get_dummies(data=X_train_CV, columns=['year','hour','min','dayweek'])\n",
    "\n",
    "a = X_train_1.shape[0]\n",
    "b = X_train_CV.shape[0]\n",
    "skf_is = ([np.arange(a-b).astype(int),np.arange(a-b,a).astype(int)])\n",
    "\n",
    "train_test_model_clf(X_train_1, y_df, skf_is, FeatureExtractor, Regressor, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
